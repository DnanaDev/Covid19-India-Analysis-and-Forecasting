{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/beginners-introduction-postgresql#comments\n",
    "<br>\n",
    "#### TO DO\n",
    "1. Modularise code. \n",
    "2. Add append logic for tables. \n",
    "3. Connect to Google Cloud SQL etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing SQL using magic Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the SQL extension in jupyter notebook\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://postgres:Anand1996@localhost:5432/Covid19-India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/Covid19-India\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the table and create it again \n",
    "\n",
    "%sql DROP table overall_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/Covid19-India\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE overall_stats(\n",
    "date DATE PRIMARY KEY,\n",
    "DailyConfirmed INT NOT NULL,\n",
    "DailyDeceased INT NOT NULL,\n",
    "DailyRecovered INT NOT NULL,\n",
    "TotalConfirmed INT NOT NULL,\n",
    "TotalDeceased INT NOT NULL,\n",
    "TotalRecovered INT NOT NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_table(limit_rows):\n",
    "    \"\"\"querying table using magic function\n",
    "    can be embedded with python code and can also insert python vars etc. within {}\n",
    "    \"\"\"\n",
    "    \n",
    "    %sql SELECT * FROM overall_stats LIMIT {limit_rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/Covid19-India\n",
      "0 rows affected.\n"
     ]
    }
   ],
   "source": [
    "query_table(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing your database through your Python code \n",
    "https://docs.sqlalchemy.org/en/13/ <br>\n",
    "SQLAlchemy provides a more suitable engine to interface with your RDBMS.\n",
    "Supported Dialects :\n",
    "PostgreSQL | MySQL | SQLite | Oracle | Microsoft SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preparing DataFrames, The Idea is to run the Ingestion Script with all fetching \n",
    "# fucntions and save function to true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from Covid19_india_org_api import make_dataframe, get_test_dataframe, make_state_dataframe\n",
    "from psycopg2 import ProgrammingError, errors, IntegrityError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_overall_stats(engine):\n",
    "    \"\"\" Initial setup of overall_stats table according to Schema\n",
    "    (rigid, hard-coded, can cause problems) - consult others. \n",
    "    \"\"\"\n",
    "    # Creating Overall_stats table\n",
    "    engine.execute(\"\"\" CREATE TABLE overall_stats(\n",
    "                \"Date\" DATE PRIMARY KEY,\n",
    "                \"DailyConfirmed\" INT NOT NULL,\n",
    "                \"DailyDeceased\" INT NOT NULL,\n",
    "                \"DailyRecovered\" INT NOT NULL,\n",
    "                \"TotalConfirmed\" INT NOT NULL,\n",
    "                \"TotalDeceased\" INT NOT NULL,\n",
    "                \"TotalRecovered\" INT NOT NULL\n",
    "                )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_testing_stats(engine):\n",
    "    \"\"\" Initial setup of testing_stats table\n",
    "    \"\"\"\n",
    "# Creating testing stats table\n",
    "    engine.execute(\"\"\" CREATE TABLE testing_stats(\n",
    "                \"Date\" DATE PRIMARY KEY,\n",
    "                \"TestingSamples\" INT NOT NULL,\n",
    "                FOREIGN KEY(\"Date\")\n",
    "                    REFERENCES overall_stats(\"Date\")\n",
    "                )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_state_info(engine):\n",
    "    \"\"\" Initial setup of state_info table, using pandas.DF.to_sql to create schema and adding\n",
    "    keys later due to the number of columns. \n",
    "    \"\"\"\n",
    "    # Creating state_info table\n",
    "    engine.execute(\"\"\"CREATE TABLE \"states_info\" (\n",
    "    \"Date\" DATE PRIMARY KEY,\n",
    "    \"Total.Confirmed\" INTEGER,\n",
    "      \"Total.Deceased\" INTEGER,\n",
    "      \"Total.Recovered\" INTEGER,\n",
    "      \"AndamanAndNicobarIslands.Confirmed\" INTEGER,\n",
    "      \"AndamanAndNicobarIslands.Deceased\" INTEGER,\n",
    "      \"AndamanAndNicobarIslands.Recovered\" INTEGER,\n",
    "      \"AndhraPradesh.Confirmed\" INTEGER,\n",
    "      \"AndhraPradesh.Deceased\" INTEGER,\n",
    "      \"AndhraPradesh.Recovered\" INTEGER,\n",
    "      \"ArunachalPradesh.Confirmed\" INTEGER,\n",
    "      \"ArunachalPradesh.Deceased\" INTEGER,\n",
    "      \"ArunachalPradesh.Recovered\" INTEGER,\n",
    "      \"Assam.Confirmed\" INTEGER,\n",
    "      \"Assam.Deceased\" INTEGER,\n",
    "      \"Assam.Recovered\" INTEGER,\n",
    "      \"Bihar.Confirmed\" INTEGER,\n",
    "      \"Bihar.Deceased\" INTEGER,\n",
    "      \"Bihar.Recovered\" INTEGER,\n",
    "      \"Chandigarh.Confirmed\" INTEGER,\n",
    "      \"Chandigarh.Deceased\" INTEGER,\n",
    "      \"Chandigarh.Recovered\" INTEGER,\n",
    "      \"Chhattisgarh.Confirmed\" INTEGER,\n",
    "      \"Chhattisgarh.Deceased\" INTEGER,\n",
    "      \"Chhattisgarh.Recovered\" INTEGER,\n",
    "      \"DadraAndNagarHaveliAndDamanAndDiu.Confirmed\" INTEGER,\n",
    "      \"DadraAndNagarHaveliAndDamanAndDiu.Deceased\" INTEGER,\n",
    "      \"DadraAndNagarHaveliAndDamanAndDiu.Recovered\" INTEGER,\n",
    "      \"Dd.Confirmed\" INTEGER,\n",
    "      \"Dd.Deceased\" INTEGER,\n",
    "      \"Dd.Recovered\" INTEGER,\n",
    "      \"Delhi.Confirmed\" INTEGER,\n",
    "      \"Delhi.Deceased\" INTEGER,\n",
    "      \"Delhi.Recovered\" INTEGER,\n",
    "      \"Goa.Confirmed\" INTEGER,\n",
    "      \"Goa.Deceased\" INTEGER,\n",
    "      \"Goa.Recovered\" INTEGER,\n",
    "      \"Gujarat.Confirmed\" INTEGER,\n",
    "      \"Gujarat.Deceased\" INTEGER,\n",
    "      \"Gujarat.Recovered\" INTEGER,\n",
    "      \"Haryana.Confirmed\" INTEGER,\n",
    "      \"Haryana.Deceased\" INTEGER,\n",
    "      \"Haryana.Recovered\" INTEGER,\n",
    "      \"HimachalPradesh.Confirmed\" INTEGER,\n",
    "      \"HimachalPradesh.Deceased\" INTEGER,\n",
    "      \"HimachalPradesh.Recovered\" INTEGER,\n",
    "      \"JammuAndKashmir.Confirmed\" INTEGER,\n",
    "      \"JammuAndKashmir.Deceased\" INTEGER,\n",
    "      \"JammuAndKashmir.Recovered\" INTEGER,\n",
    "      \"Jharkhand.Confirmed\" INTEGER,\n",
    "      \"Jharkhand.Deceased\" INTEGER,\n",
    "      \"Jharkhand.Recovered\" INTEGER,\n",
    "      \"Karnataka.Confirmed\" INTEGER,\n",
    "      \"Karnataka.Deceased\" INTEGER,\n",
    "      \"Karnataka.Recovered\" INTEGER,\n",
    "      \"Kerala.Confirmed\" INTEGER,\n",
    "      \"Kerala.Deceased\" INTEGER,\n",
    "      \"Kerala.Recovered\" INTEGER,\n",
    "      \"Ladakh.Confirmed\" INTEGER,\n",
    "      \"Ladakh.Deceased\" INTEGER,\n",
    "      \"Ladakh.Recovered\" INTEGER,\n",
    "      \"Lakshadweep.Confirmed\" INTEGER,\n",
    "      \"Lakshadweep.Deceased\" INTEGER,\n",
    "      \"Lakshadweep.Recovered\" INTEGER,\n",
    "      \"MadhyaPradesh.Confirmed\" INTEGER,\n",
    "      \"MadhyaPradesh.Deceased\" INTEGER,\n",
    "      \"MadhyaPradesh.Recovered\" INTEGER,\n",
    "      \"Maharashtra.Confirmed\" INTEGER,\n",
    "      \"Maharashtra.Deceased\" INTEGER,\n",
    "      \"Maharashtra.Recovered\" INTEGER,\n",
    "      \"Manipur.Confirmed\" INTEGER,\n",
    "      \"Manipur.Deceased\" INTEGER,\n",
    "      \"Manipur.Recovered\" INTEGER,\n",
    "      \"Meghalaya.Confirmed\" INTEGER,\n",
    "      \"Meghalaya.Deceased\" INTEGER,\n",
    "      \"Meghalaya.Recovered\" INTEGER,\n",
    "      \"Mizoram.Confirmed\" INTEGER,\n",
    "      \"Mizoram.Deceased\" INTEGER,\n",
    "      \"Mizoram.Recovered\" INTEGER,\n",
    "      \"Nagaland.Confirmed\" INTEGER,\n",
    "      \"Nagaland.Deceased\" INTEGER,\n",
    "      \"Nagaland.Recovered\" INTEGER,\n",
    "      \"Odisha.Confirmed\" INTEGER,\n",
    "      \"Odisha.Deceased\" INTEGER,\n",
    "      \"Odisha.Recovered\" INTEGER,\n",
    "      \"Puducherry.Confirmed\" INTEGER,\n",
    "      \"Puducherry.Deceased\" INTEGER,\n",
    "      \"Puducherry.Recovered\" INTEGER,\n",
    "      \"Punjab.Confirmed\" INTEGER,\n",
    "      \"Punjab.Deceased\" INTEGER,\n",
    "      \"Punjab.Recovered\" INTEGER,\n",
    "      \"Rajasthan.Confirmed\" INTEGER,\n",
    "      \"Rajasthan.Deceased\" INTEGER,\n",
    "      \"Rajasthan.Recovered\" INTEGER,\n",
    "      \"Sikkim.Confirmed\" INTEGER,\n",
    "      \"Sikkim.Deceased\" INTEGER,\n",
    "      \"Sikkim.Recovered\" INTEGER,\n",
    "      \"TamilNadu.Confirmed\" INTEGER,\n",
    "      \"TamilNadu.Deceased\" INTEGER,\n",
    "      \"TamilNadu.Recovered\" INTEGER,\n",
    "      \"Telangana.Confirmed\" INTEGER,\n",
    "      \"Telangana.Deceased\" INTEGER,\n",
    "      \"Telangana.Recovered\" INTEGER,\n",
    "      \"Tripura.Confirmed\" INTEGER,\n",
    "      \"Tripura.Deceased\" INTEGER,\n",
    "      \"Tripura.Recovered\" INTEGER,\n",
    "      \"UttarPradesh.Confirmed\" INTEGER,\n",
    "      \"UttarPradesh.Deceased\" INTEGER,\n",
    "      \"UttarPradesh.Recovered\" INTEGER,\n",
    "      \"Uttarakhand.Confirmed\" INTEGER,\n",
    "      \"Uttarakhand.Deceased\" INTEGER,\n",
    "      \"Uttarakhand.Recovered\" INTEGER,\n",
    "      \"WestBengal.Confirmed\" INTEGER,\n",
    "      \"WestBengal.Deceased\" INTEGER,\n",
    "      \"WestBengal.Recovered\" INTEGER,\n",
    "      \"StateUnassigned.Confirmed\" INTEGER,\n",
    "      \"StateUnassigned.Deceased\" INTEGER,\n",
    "      \"StateUnassigned.Recovered\" INTEGER,\n",
    "       FOREIGN KEY(\"Date\")\n",
    "       REFERENCES overall_stats(\"Date\")\n",
    "    )\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append problem, duplicate key values. Shouldn't happen with append but here we are.\n",
    "# workaround. fetch length of existing records in table and then only store records after that. Can be problematic.\n",
    "# Cannot replace due to the presence of foreign key.\n",
    "\n",
    "def add_data_table(engine, tablename, df):\n",
    "    \"\"\" Appends New Data to table if it exists\n",
    "    Takes in engine connected to DB, tablename and dataframe to store.\n",
    "    Throws error if 1. Table Doesn't Exist, 2. incorrect table and dataframe ?(abstract this coice away from user)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = engine.execute(f\"\"\"SELECT * FROM {tablename}\"\"\")\n",
    "        num_records = len(results.fetchall())\n",
    "        print(f'{num_records} Records in {tablename}')\n",
    "\n",
    "        df[num_records:].to_sql(tablename, engine, if_exists='append')\n",
    "        print(f'Added {len(df[num_records:])} Records to table')\n",
    "    \n",
    "    # Just can't seem to get errors to work \n",
    "    except IntegrityError as e:\n",
    "        print(e)\n",
    "        if err == IntegrityError :\n",
    "            print('Update Master Table first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function - Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating engine for executing sql queries\n",
    "engine = create_engine('postgresql://postgres:Anand1996@localhost:5432/Covid19-India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Tables \n",
    "create_table_overall_stats(engine)\n",
    "create_table_testing_stats(engine)\n",
    "create_table_state_info(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingesting overall stats data \n",
    "data = make_dataframe(save= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 Records in overall_stats\n",
      "Added 1 Records to table\n"
     ]
    }
   ],
   "source": [
    "add_data_table(engine, 'overall_stats', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 Records in testing_stats\n",
      "Added 0 Records to table\n"
     ]
    }
   ],
   "source": [
    "# Ingesting Testing Data \n",
    "\n",
    "# test has duplicates for a single date, will fail the unique constraint for key, remove first.\n",
    "test = get_test_dataframe(save=True)\n",
    "test = test.loc[~test.index.duplicated(keep='last')]\n",
    "add_data_table(engine, 'testing_stats', test[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 Records in states_info\n",
      "Added 1 Records to table\n"
     ]
    }
   ],
   "source": [
    "# Ingesting State column\n",
    "\n",
    "state = make_state_dataframe(save=True)\n",
    "\n",
    "# Creating a flat column index\n",
    "cols = state.columns.get_level_values(0).str.title() + '.' + state.columns.get_level_values(1)\n",
    "state.columns = cols\n",
    "state.columns = state.columns.str.replace(' ', '')\n",
    "\n",
    "add_data_table(engine, 'states_info', state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping PostgreSQL DB\n",
    "Backed up using GUI for now. <br>\n",
    "https://www.postgresqltutorial.com/postgresql-backup-database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pg_dump', '--host=localhost', '--dbname=Covid19-India', '--username=postgres', '--no-password', '--format=p', '--file=/Users/apple/Desktop/DS/Covid19-Kaggle_and_End-End_project/Data/Cleaned/Covid19-India_backup.sql'], returncode=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['pg_dump', '--host=localhost', '--dbname=Covid19-India',\n",
    "                '--username=postgres', '--no-password','--format=p',\n",
    "                '--file=/Users/apple/Desktop/DS/Covid19-Kaggle_and_End-End_project/Data/Cleaned/Covid19-India_backup.sql'])"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Data_ingestion.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
