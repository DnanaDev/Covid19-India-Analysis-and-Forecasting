{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/beginners-introduction-postgresql#comments\n",
    "<br>\n",
    "#### TO DO \n",
    "1. Convert Table state info to 5 columns - date, state, Confirmed, Recovered, Deceased (Primary Key combination of Date and State) instead of the super long format you have right now. (Done ! - Document and Refactor) \n",
    "2. Connect to Google Cloud SQL etc. (Created Online Instance)\n",
    "<br><b>GCP PostgreSQL CLoud Instance Details: </b><br>\n",
    "covid19-data-server<br>\n",
    "<Pass>\n",
    "3. Convert Ingestion Function for Use with Cloud Function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Accessing SQL using magic Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load the SQL extension in jupyter notebook\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# connecting to local PostgreSql Server\n",
    "%sql postgresql://postgres:<Pass>@localhost:5432/Covid19-India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postgresql://postgres:***@localhost:5432/Covid19-India\n",
      " * postgresql://postgres:***@localhost:5433/covid19-data\n",
      "133 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Date</th>\n",
       "        <th>TestingSamples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-13</td>\n",
       "        <td>6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-18</td>\n",
       "        <td>13125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-19</td>\n",
       "        <td>14175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-20</td>\n",
       "        <td>15404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-21</td>\n",
       "        <td>15701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-22</td>\n",
       "        <td>16999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-23</td>\n",
       "        <td>20707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-24</td>\n",
       "        <td>20864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-25</td>\n",
       "        <td>25144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-03-27</td>\n",
       "        <td>27688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-02</td>\n",
       "        <td>47951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-03</td>\n",
       "        <td>69245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-04</td>\n",
       "        <td>79950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-05</td>\n",
       "        <td>89534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-06</td>\n",
       "        <td>101068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-07</td>\n",
       "        <td>114015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-08</td>\n",
       "        <td>127919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-09</td>\n",
       "        <td>144910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-10</td>\n",
       "        <td>161330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-11</td>\n",
       "        <td>179374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-12</td>\n",
       "        <td>195748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-13</td>\n",
       "        <td>217554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-14</td>\n",
       "        <td>244893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-15</td>\n",
       "        <td>274599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-16</td>\n",
       "        <td>302956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-17</td>\n",
       "        <td>335123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-18</td>\n",
       "        <td>372123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-19</td>\n",
       "        <td>401586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-21</td>\n",
       "        <td>462621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-23</td>\n",
       "        <td>500542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-24</td>\n",
       "        <td>541789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-25</td>\n",
       "        <td>579957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-26</td>\n",
       "        <td>625309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-27</td>\n",
       "        <td>665819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-28</td>\n",
       "        <td>716733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-29</td>\n",
       "        <td>770764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-04-30</td>\n",
       "        <td>830201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-01</td>\n",
       "        <td>902654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-02</td>\n",
       "        <td>976363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-03</td>\n",
       "        <td>1046450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-04</td>\n",
       "        <td>1107233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-05</td>\n",
       "        <td>1191946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-06</td>\n",
       "        <td>1276781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-07</td>\n",
       "        <td>1357413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-08</td>\n",
       "        <td>1437788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-09</td>\n",
       "        <td>1523213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-10</td>\n",
       "        <td>1609037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-11</td>\n",
       "        <td>1673688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-12</td>\n",
       "        <td>1759579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-13</td>\n",
       "        <td>1854250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-14</td>\n",
       "        <td>1947041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-15</td>\n",
       "        <td>2039952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-16</td>\n",
       "        <td>2134277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-17</td>\n",
       "        <td>2227642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-18</td>\n",
       "        <td>2302792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-19</td>\n",
       "        <td>2404267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-20</td>\n",
       "        <td>2512388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-21</td>\n",
       "        <td>2615920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-22</td>\n",
       "        <td>2719434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-23</td>\n",
       "        <td>2834798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-24</td>\n",
       "        <td>2943421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-25</td>\n",
       "        <td>3033591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-26</td>\n",
       "        <td>3126119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-27</td>\n",
       "        <td>3242160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-28</td>\n",
       "        <td>3362136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-29</td>\n",
       "        <td>3483838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-30</td>\n",
       "        <td>3611599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-05-31</td>\n",
       "        <td>3737027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-01</td>\n",
       "        <td>3837207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-02</td>\n",
       "        <td>3966075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-03</td>\n",
       "        <td>4103233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-04</td>\n",
       "        <td>4242718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-05</td>\n",
       "        <td>4386379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-06</td>\n",
       "        <td>4524317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-07</td>\n",
       "        <td>4666386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-08</td>\n",
       "        <td>4774434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-09</td>\n",
       "        <td>4916116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-10</td>\n",
       "        <td>5061332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-11</td>\n",
       "        <td>5213140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-12</td>\n",
       "        <td>5363445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-13</td>\n",
       "        <td>5507182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-14</td>\n",
       "        <td>5658614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-15</td>\n",
       "        <td>5774133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-16</td>\n",
       "        <td>5921069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-17</td>\n",
       "        <td>6084256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-18</td>\n",
       "        <td>6249668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-19</td>\n",
       "        <td>6426627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-20</td>\n",
       "        <td>6616496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-21</td>\n",
       "        <td>6807226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-22</td>\n",
       "        <td>6950493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-23</td>\n",
       "        <td>7137716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-24</td>\n",
       "        <td>7352911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-25</td>\n",
       "        <td>7560782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-26</td>\n",
       "        <td>7776228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-27</td>\n",
       "        <td>7996707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-28</td>\n",
       "        <td>8227802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-29</td>\n",
       "        <td>8398362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-06-30</td>\n",
       "        <td>8608654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-01</td>\n",
       "        <td>8826585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-02</td>\n",
       "        <td>9056173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-03</td>\n",
       "        <td>9297749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-04</td>\n",
       "        <td>9540132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-05</td>\n",
       "        <td>9789066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-06</td>\n",
       "        <td>9969662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-07</td>\n",
       "        <td>10211092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-08</td>\n",
       "        <td>10473771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-09</td>\n",
       "        <td>10740832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-10</td>\n",
       "        <td>11024491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-11</td>\n",
       "        <td>11307002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-12</td>\n",
       "        <td>11587153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-13</td>\n",
       "        <td>11806256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-14</td>\n",
       "        <td>12092503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-15</td>\n",
       "        <td>12412664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-16</td>\n",
       "        <td>12739490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-17</td>\n",
       "        <td>13072718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-18</td>\n",
       "        <td>13433742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-19</td>\n",
       "        <td>13791869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-20</td>\n",
       "        <td>14047908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-21</td>\n",
       "        <td>14381303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-22</td>\n",
       "        <td>14724546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-23</td>\n",
       "        <td>15075369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-24</td>\n",
       "        <td>15428170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-25</td>\n",
       "        <td>15849068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-26</td>\n",
       "        <td>16291331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-27</td>\n",
       "        <td>16806803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-28</td>\n",
       "        <td>17334885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-29</td>\n",
       "        <td>17743740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-30</td>\n",
       "        <td>18190382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-07-31</td>\n",
       "        <td>18832970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-08-01</td>\n",
       "        <td>19358659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-08-02</td>\n",
       "        <td>19821831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-08-03</td>\n",
       "        <td>20202858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2020-08-04</td>\n",
       "        <td>20864750</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.date(2020, 3, 13), 6500),\n",
       " (datetime.date(2020, 3, 18), 13125),\n",
       " (datetime.date(2020, 3, 19), 14175),\n",
       " (datetime.date(2020, 3, 20), 15404),\n",
       " (datetime.date(2020, 3, 21), 15701),\n",
       " (datetime.date(2020, 3, 22), 16999),\n",
       " (datetime.date(2020, 3, 23), 20707),\n",
       " (datetime.date(2020, 3, 24), 20864),\n",
       " (datetime.date(2020, 3, 25), 25144),\n",
       " (datetime.date(2020, 3, 27), 27688),\n",
       " (datetime.date(2020, 4, 2), 47951),\n",
       " (datetime.date(2020, 4, 3), 69245),\n",
       " (datetime.date(2020, 4, 4), 79950),\n",
       " (datetime.date(2020, 4, 5), 89534),\n",
       " (datetime.date(2020, 4, 6), 101068),\n",
       " (datetime.date(2020, 4, 7), 114015),\n",
       " (datetime.date(2020, 4, 8), 127919),\n",
       " (datetime.date(2020, 4, 9), 144910),\n",
       " (datetime.date(2020, 4, 10), 161330),\n",
       " (datetime.date(2020, 4, 11), 179374),\n",
       " (datetime.date(2020, 4, 12), 195748),\n",
       " (datetime.date(2020, 4, 13), 217554),\n",
       " (datetime.date(2020, 4, 14), 244893),\n",
       " (datetime.date(2020, 4, 15), 274599),\n",
       " (datetime.date(2020, 4, 16), 302956),\n",
       " (datetime.date(2020, 4, 17), 335123),\n",
       " (datetime.date(2020, 4, 18), 372123),\n",
       " (datetime.date(2020, 4, 19), 401586),\n",
       " (datetime.date(2020, 4, 21), 462621),\n",
       " (datetime.date(2020, 4, 23), 500542),\n",
       " (datetime.date(2020, 4, 24), 541789),\n",
       " (datetime.date(2020, 4, 25), 579957),\n",
       " (datetime.date(2020, 4, 26), 625309),\n",
       " (datetime.date(2020, 4, 27), 665819),\n",
       " (datetime.date(2020, 4, 28), 716733),\n",
       " (datetime.date(2020, 4, 29), 770764),\n",
       " (datetime.date(2020, 4, 30), 830201),\n",
       " (datetime.date(2020, 5, 1), 902654),\n",
       " (datetime.date(2020, 5, 2), 976363),\n",
       " (datetime.date(2020, 5, 3), 1046450),\n",
       " (datetime.date(2020, 5, 4), 1107233),\n",
       " (datetime.date(2020, 5, 5), 1191946),\n",
       " (datetime.date(2020, 5, 6), 1276781),\n",
       " (datetime.date(2020, 5, 7), 1357413),\n",
       " (datetime.date(2020, 5, 8), 1437788),\n",
       " (datetime.date(2020, 5, 9), 1523213),\n",
       " (datetime.date(2020, 5, 10), 1609037),\n",
       " (datetime.date(2020, 5, 11), 1673688),\n",
       " (datetime.date(2020, 5, 12), 1759579),\n",
       " (datetime.date(2020, 5, 13), 1854250),\n",
       " (datetime.date(2020, 5, 14), 1947041),\n",
       " (datetime.date(2020, 5, 15), 2039952),\n",
       " (datetime.date(2020, 5, 16), 2134277),\n",
       " (datetime.date(2020, 5, 17), 2227642),\n",
       " (datetime.date(2020, 5, 18), 2302792),\n",
       " (datetime.date(2020, 5, 19), 2404267),\n",
       " (datetime.date(2020, 5, 20), 2512388),\n",
       " (datetime.date(2020, 5, 21), 2615920),\n",
       " (datetime.date(2020, 5, 22), 2719434),\n",
       " (datetime.date(2020, 5, 23), 2834798),\n",
       " (datetime.date(2020, 5, 24), 2943421),\n",
       " (datetime.date(2020, 5, 25), 3033591),\n",
       " (datetime.date(2020, 5, 26), 3126119),\n",
       " (datetime.date(2020, 5, 27), 3242160),\n",
       " (datetime.date(2020, 5, 28), 3362136),\n",
       " (datetime.date(2020, 5, 29), 3483838),\n",
       " (datetime.date(2020, 5, 30), 3611599),\n",
       " (datetime.date(2020, 5, 31), 3737027),\n",
       " (datetime.date(2020, 6, 1), 3837207),\n",
       " (datetime.date(2020, 6, 2), 3966075),\n",
       " (datetime.date(2020, 6, 3), 4103233),\n",
       " (datetime.date(2020, 6, 4), 4242718),\n",
       " (datetime.date(2020, 6, 5), 4386379),\n",
       " (datetime.date(2020, 6, 6), 4524317),\n",
       " (datetime.date(2020, 6, 7), 4666386),\n",
       " (datetime.date(2020, 6, 8), 4774434),\n",
       " (datetime.date(2020, 6, 9), 4916116),\n",
       " (datetime.date(2020, 6, 10), 5061332),\n",
       " (datetime.date(2020, 6, 11), 5213140),\n",
       " (datetime.date(2020, 6, 12), 5363445),\n",
       " (datetime.date(2020, 6, 13), 5507182),\n",
       " (datetime.date(2020, 6, 14), 5658614),\n",
       " (datetime.date(2020, 6, 15), 5774133),\n",
       " (datetime.date(2020, 6, 16), 5921069),\n",
       " (datetime.date(2020, 6, 17), 6084256),\n",
       " (datetime.date(2020, 6, 18), 6249668),\n",
       " (datetime.date(2020, 6, 19), 6426627),\n",
       " (datetime.date(2020, 6, 20), 6616496),\n",
       " (datetime.date(2020, 6, 21), 6807226),\n",
       " (datetime.date(2020, 6, 22), 6950493),\n",
       " (datetime.date(2020, 6, 23), 7137716),\n",
       " (datetime.date(2020, 6, 24), 7352911),\n",
       " (datetime.date(2020, 6, 25), 7560782),\n",
       " (datetime.date(2020, 6, 26), 7776228),\n",
       " (datetime.date(2020, 6, 27), 7996707),\n",
       " (datetime.date(2020, 6, 28), 8227802),\n",
       " (datetime.date(2020, 6, 29), 8398362),\n",
       " (datetime.date(2020, 6, 30), 8608654),\n",
       " (datetime.date(2020, 7, 1), 8826585),\n",
       " (datetime.date(2020, 7, 2), 9056173),\n",
       " (datetime.date(2020, 7, 3), 9297749),\n",
       " (datetime.date(2020, 7, 4), 9540132),\n",
       " (datetime.date(2020, 7, 5), 9789066),\n",
       " (datetime.date(2020, 7, 6), 9969662),\n",
       " (datetime.date(2020, 7, 7), 10211092),\n",
       " (datetime.date(2020, 7, 8), 10473771),\n",
       " (datetime.date(2020, 7, 9), 10740832),\n",
       " (datetime.date(2020, 7, 10), 11024491),\n",
       " (datetime.date(2020, 7, 11), 11307002),\n",
       " (datetime.date(2020, 7, 12), 11587153),\n",
       " (datetime.date(2020, 7, 13), 11806256),\n",
       " (datetime.date(2020, 7, 14), 12092503),\n",
       " (datetime.date(2020, 7, 15), 12412664),\n",
       " (datetime.date(2020, 7, 16), 12739490),\n",
       " (datetime.date(2020, 7, 17), 13072718),\n",
       " (datetime.date(2020, 7, 18), 13433742),\n",
       " (datetime.date(2020, 7, 19), 13791869),\n",
       " (datetime.date(2020, 7, 20), 14047908),\n",
       " (datetime.date(2020, 7, 21), 14381303),\n",
       " (datetime.date(2020, 7, 22), 14724546),\n",
       " (datetime.date(2020, 7, 23), 15075369),\n",
       " (datetime.date(2020, 7, 24), 15428170),\n",
       " (datetime.date(2020, 7, 25), 15849068),\n",
       " (datetime.date(2020, 7, 26), 16291331),\n",
       " (datetime.date(2020, 7, 27), 16806803),\n",
       " (datetime.date(2020, 7, 28), 17334885),\n",
       " (datetime.date(2020, 7, 29), 17743740),\n",
       " (datetime.date(2020, 7, 30), 18190382),\n",
       " (datetime.date(2020, 7, 31), 18832970),\n",
       " (datetime.date(2020, 8, 1), 19358659),\n",
       " (datetime.date(2020, 8, 2), 19821831),\n",
       " (datetime.date(2020, 8, 3), 20202858),\n",
       " (datetime.date(2020, 8, 4), 20864750)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM testing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/Covid19-India\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the table and create it again \n",
    "\n",
    "%sql DROP table overall_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/Covid19-India\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE overall_stats(\n",
    "date DATE PRIMARY KEY,\n",
    "DailyConfirmed INT NOT NULL,\n",
    "DailyDeceased INT NOT NULL,\n",
    "DailyRecovered INT NOT NULL,\n",
    "TotalConfirmed INT NOT NULL,\n",
    "TotalDeceased INT NOT NULL,\n",
    "TotalRecovered INT NOT NULL\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def query_table(limit_rows):\n",
    "    \"\"\"querying table using magic function\n",
    "    can be embedded with python code and can also insert python vars etc. within {}\n",
    "    \"\"\"\n",
    "    \n",
    "    %sql SELECT * FROM overall_stats LIMIT {limit_rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/Covid19-India\n",
      "0 rows affected.\n"
     ]
    }
   ],
   "source": [
    "query_table(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Local database through your Python code Using SQLAlchemy\n",
    "https://docs.sqlalchemy.org/en/13/ <br>\n",
    "SQLAlchemy provides a more suitable engine to interface with your RDBMS.\n",
    "Supported Dialects :\n",
    "PostgreSQL | MySQL | SQLite | Oracle | Microsoft SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preparing DataFrames, The Idea is to run the Ingestion Script with all fetching \n",
    "# fucntions and save function to true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from Covid19_india_org_api import make_dataframe, get_test_dataframe, make_state_dataframe\n",
    "from psycopg2 import ProgrammingError, errors, IntegrityError\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_overall_stats(engine):\n",
    "    \"\"\" Initial setup of overall_stats table according to Schema\n",
    "    (rigid, hard-coded, can cause problems) - consult others. \n",
    "    \"\"\"\n",
    "    # Creating Overall_stats table\n",
    "    engine.execute(\"\"\" CREATE TABLE overall_stats(\n",
    "                \"Date\" DATE PRIMARY KEY,\n",
    "                \"DailyConfirmed\" INT NOT NULL,\n",
    "                \"DailyDeceased\" INT NOT NULL,\n",
    "                \"DailyRecovered\" INT NOT NULL,\n",
    "                \"TotalConfirmed\" INT NOT NULL,\n",
    "                \"TotalDeceased\" INT NOT NULL,\n",
    "                \"TotalRecovered\" INT NOT NULL\n",
    "                )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_testing_stats(engine):\n",
    "    \"\"\" Initial setup of testing_stats table.\n",
    "    \"\"\"\n",
    "# Creating testing stats table\n",
    "    engine.execute(\"\"\" CREATE TABLE testing_stats(\n",
    "                \"Date\" DATE PRIMARY KEY,\n",
    "                \"TestingSamples\" INT NOT NULL,\n",
    "                FOREIGN KEY(\"Date\")\n",
    "                    REFERENCES overall_stats(\"Date\")\n",
    "                )\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_state_info(engine):\n",
    "    \"\"\" Initial setup of state_info table, used pandas.io.sql.get_schema to create schema and added\n",
    "    keys later due to the number of columns. \n",
    "    \"\"\"\n",
    "    # Creating state_info table\n",
    "    engine.execute(\"\"\"CREATE TABLE \"states_info\" (\n",
    "    \"Date\" DATE ,\n",
    "    \"State\" TEXT,\n",
    "    \"Confirmed\" INTEGER,\n",
    "    \"Deceased\" INTEGER,\n",
    "    \"Recovered\" INTEGER,\n",
    "    PRIMARY KEY(\"Date\", \"State\"),\n",
    "    FOREIGN KEY(\"Date\")\n",
    "    REFERENCES overall_stats(\"Date\")\n",
    "    )\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Ingestion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append problem, duplicate key values. Shouldn't happen with append but here we are.\n",
    "# workaround. fetch length of existing records in table and then only store records after that. Can be problematic.\n",
    "# Cannot replace due to the presence of foreign key.\n",
    "\n",
    "def add_data_table(engine, tablename, df):\n",
    "    \"\"\" Appends New Data to table if it exists\n",
    "    Takes in engine connected to DB, tablename and dataframe to store.\n",
    "    Throws error if 1. Table Doesn't Exist, 2. incorrect table and dataframe ?(abstract this coice away from user)\n",
    "    Problematic for testing_table as it has duplicates. - Possible solution, find last index and not length.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = engine.execute(f\"\"\"SELECT * FROM {tablename}\"\"\")\n",
    "        num_records = len(results.fetchall())\n",
    "        print(f'{num_records} Records in {tablename}')\n",
    "\n",
    "        df[num_records:].to_sql(tablename, engine, if_exists='append')\n",
    "        print(f'Added {len(df[num_records:])} Records to table')\n",
    "    \n",
    "    # Just can't seem to get errors to work \n",
    "    except IntegrityError as e:\n",
    "        print(e)\n",
    "        if err == IntegrityError :\n",
    "            print('Update Master Table first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Function - Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating engine for executing sql queries\n",
    "engine = create_engine('postgresql://postgres:<Pass>@localhost:5432/Covid19-India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Tables \n",
    "create_table_overall_stats(engine)\n",
    "create_table_testing_stats(engine)\n",
    "create_table_state_info(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingesting overall stats data \n",
    "data = make_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Records in overall_stats\n",
      "Added 187 Records to table\n"
     ]
    }
   ],
   "source": [
    "add_data_table(engine, 'overall_stats', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Records in testing_stats\n",
      "Added 131 Records to table\n"
     ]
    }
   ],
   "source": [
    "# Ingesting Testing Data \n",
    "\n",
    "# test has duplicates for a single date, will fail the unique constraint for key, remove first.\n",
    "test = get_test_dataframe()\n",
    "test = test.loc[~test.index.duplicated(keep='last')]\n",
    "add_data_table(engine, 'testing_stats', test[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Records in states_info\n",
      "Added 5577 Records to table\n"
     ]
    }
   ],
   "source": [
    "# Ingesting State column\n",
    "\n",
    "states = make_state_dataframe()\n",
    "\n",
    "add_data_table(engine, 'states_info', states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Dumping PostgreSQL DB\n",
    "Backed up using GUI for now. <br>\n",
    "https://www.postgresqltutorial.com/postgresql-backup-database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def backup_dB(path):\n",
    "    subprocess.run(['pg_dump', '--host=localhost', '--dbname=Covid19-India',\n",
    "                    '--username=postgres', '--no-password','--format=p',\n",
    "                    f'--file={path}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backup_dB('/Users/apple/Desktop/DS/Covid19-Kaggle_and_End-End_project/Data/Cleaned/Covid19-India_backup.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Google Cloud SQL Server\n",
    "1. Create sql Alchemy engine and connect to CloudSQL Server. (Make sure instance in running and Cloud SQL Proxy is active)\n",
    "2. cloud_sql_proxy needs to be running and set-up on client server.(Less painful method ? - Giving Access to public IP was not working.)\n",
    "3. Simply Use Pandas and SqlAlchemy to fetch the data.\n",
    "4. Able to update Tables this way too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:<pass>@localhost:5433/covid19-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_sql('SELECT * FROM states_info', engine , parse_dates = True, index_col ='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_sql('SELECT * FROM testing_stats', engine , parse_dates = True, index_col ='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.read_sql('SELECT * FROM overall_stats', engine, parse_dates = True, index_col ='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyConfirmed</th>\n",
       "      <th>DailyDeceased</th>\n",
       "      <th>DailyRecovered</th>\n",
       "      <th>TotalConfirmed</th>\n",
       "      <th>TotalDeceased</th>\n",
       "      <th>TotalRecovered</th>\n",
       "      <th>TestingSamples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-02</th>\n",
       "      <td>52672</td>\n",
       "      <td>760</td>\n",
       "      <td>40355</td>\n",
       "      <td>1804857</td>\n",
       "      <td>38180</td>\n",
       "      <td>1187261</td>\n",
       "      <td>19821831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-03</th>\n",
       "      <td>50475</td>\n",
       "      <td>806</td>\n",
       "      <td>43070</td>\n",
       "      <td>1855332</td>\n",
       "      <td>38986</td>\n",
       "      <td>1230331</td>\n",
       "      <td>20202858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-04</th>\n",
       "      <td>51282</td>\n",
       "      <td>849</td>\n",
       "      <td>51220</td>\n",
       "      <td>1906627</td>\n",
       "      <td>39835</td>\n",
       "      <td>1281551</td>\n",
       "      <td>20864750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-05</th>\n",
       "      <td>56626</td>\n",
       "      <td>919</td>\n",
       "      <td>45583</td>\n",
       "      <td>1963253</td>\n",
       "      <td>40754</td>\n",
       "      <td>1327134</td>\n",
       "      <td>21484402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-06</th>\n",
       "      <td>62170</td>\n",
       "      <td>899</td>\n",
       "      <td>50141</td>\n",
       "      <td>2025423</td>\n",
       "      <td>41653</td>\n",
       "      <td>1377275</td>\n",
       "      <td>22149351.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DailyConfirmed  DailyDeceased  DailyRecovered  TotalConfirmed  \\\n",
       "Date                                                                        \n",
       "2020-01-30               1              0               0               1   \n",
       "2020-01-31               0              0               0               1   \n",
       "2020-02-01               0              0               0               1   \n",
       "2020-02-02               1              0               0               2   \n",
       "2020-02-03               1              0               0               3   \n",
       "...                    ...            ...             ...             ...   \n",
       "2020-08-02           52672            760           40355         1804857   \n",
       "2020-08-03           50475            806           43070         1855332   \n",
       "2020-08-04           51282            849           51220         1906627   \n",
       "2020-08-05           56626            919           45583         1963253   \n",
       "2020-08-06           62170            899           50141         2025423   \n",
       "\n",
       "            TotalDeceased  TotalRecovered  TestingSamples  \n",
       "Date                                                       \n",
       "2020-01-30              0               0             NaN  \n",
       "2020-01-31              0               0             NaN  \n",
       "2020-02-01              0               0             NaN  \n",
       "2020-02-02              0               0             NaN  \n",
       "2020-02-03              0               0             NaN  \n",
       "...                   ...             ...             ...  \n",
       "2020-08-02          38180         1187261      19821831.0  \n",
       "2020-08-03          38986         1230331      20202858.0  \n",
       "2020-08-04          39835         1281551      20864750.0  \n",
       "2020-08-05          40754         1327134      21484402.0  \n",
       "2020-08-06          41653         1377275      22149351.0  \n",
       "\n",
       "[190 rows x 7 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall.join(testing, on = 'Date', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 Records in overall_stats\n",
      "Added 0 Records to table\n"
     ]
    }
   ],
   "source": [
    "add_data_table(engine, 'overall_stats', make_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data has duplicate entries, fix that.\n",
    "test = get_test_dataframe()\n",
    "test = test.loc[~test.index.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 Records in testing_stats\n",
      "Added 0 Records to table\n"
     ]
    }
   ],
   "source": [
    "add_data_table(engine, 'testing_stats', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5694 Records in states_info\n",
      "Added 0 Records to table\n"
     ]
    }
   ],
   "source": [
    "add_data_table(engine, 'states_info', make_state_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion (Raw- Bucket) to (Clean - Cloud SQL) Cloud Function\n",
    "1. Create connection to bucket. \n",
    "2. Download files from Bucket. \n",
    "3. (optional) Data validation of CSVs.- CSV validator (Validate when before Ingestion to Clean- Skipped Right now)\n",
    "4. Use Pandas as an intermediary to clean data. \n",
    "5. Create SQLAlchemy connection to CloudSQL Server.\n",
    "6. Upload Pandas DF to Cloud SQL Using SQLAlchmey.\n",
    "7. For completely empty tables and ingesting entire data to date (overall - 190, state - 5694, testing - 135 records):<br>Function execution took 22190 ms, finished with status code: 200\n",
    "8. For fetching a single day's data :<br> A. Fetch Raw Data Using fetch_raw_covid_api_data : \"Function execution took 6836 ms, finished with status code: 200\"<br>\n",
    "B. Cleaning Data and Ingesting into CloudSQl : \"Function execution took 2147 ms, finished with status code: 200\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import pg8000 # databse driver\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_folder_bucket(bucket, bucket_folder, local_folder):\n",
    "    \"\"\"Download all files from a GCS bucket folder to a local folder.\n",
    "    \"\"\"\n",
    "    # list of filenames in bucket_folder\n",
    "    file_list = [file.name for file in bucket.list_blobs(prefix=bucket_folder)]\n",
    "    \n",
    "    # iterate over blobs and doenload to local folder + filename\n",
    "\n",
    "    for file in file_list :\n",
    "        blob = bucket.blob(file)\n",
    "        # filename by splitting name by '/' and keeping last item\n",
    "        filename = blob.name.split('/')[-1]\n",
    "        # download to local folder\n",
    "        blob.download_to_filename(local_folder + filename)\n",
    "    return f'Downloaded {len(file_list)} Files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_table(engine, tablename, df):\n",
    "    \"\"\" Appends New Data to table if it exists\n",
    "    Takes in engine connected to DB, tablename and dataframe to store.\n",
    "    Throws error if 1. Table Doesn't Exist, 2. incorrect table and dataframe ?(abstract this coice away from user)\n",
    "    Problematic for testing_table as it has duplicates. - Possible solution, find last index and not length.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = engine.execute(f\"\"\"SELECT * FROM {tablename}\"\"\")\n",
    "        num_records = len(results.fetchall())\n",
    "        print(f'{num_records} Records in {tablename}')\n",
    "\n",
    "        df[num_records:].to_sql(tablename, engine, if_exists='append')\n",
    "        print(f'Added {len(df[num_records:])} Records to table')\n",
    "    \n",
    "    # Just can't seem to get errors to work \n",
    "    except :\n",
    "        print('Errored. Investigate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLAlchemy connection to CloudSQL Server.\n",
    "\n",
    "# Remember - storing secrets in plaintext is potentially unsafe.\n",
    "\n",
    "def connect_db():\n",
    "    \"\"\" Connects to Cloud SQL DB Using provided Unix Socket. Username, Password etc. Hardcoded.\n",
    "    Problematic.\n",
    "    \"\"\"\n",
    "    db_user = 'postgres'\n",
    "    db_pass = ''\n",
    "    db_name = 'covid19-data'\n",
    "    db_socket_dir = os.environ.get(\"DB_SOCKET_DIR\", \"/cloudsql\")\n",
    "    cloud_sql_connection_name = 'covid19-india-analysis-284814:asia-south1:covid19-data-server'\n",
    "\n",
    "    engine = sqlalchemy.create_engine(\n",
    "        # Equivalent URL:\n",
    "        # postgres+pg8000://<db_user>:<db_pass>@/<db_name>\n",
    "        #                         ?unix_sock=<socket_path>/<cloud_sql_instance_name>/.s.PGSQL.5432\n",
    "        sqlalchemy.engine.url.URL(\n",
    "            drivername=\"postgres+pg8000\",\n",
    "            username=db_user,  # e.g. \"my-database-user\"\n",
    "            password=db_pass,  # e.g. \"my-database-password\"\n",
    "            database=db_name,  # e.g. \"my-database-name\"\n",
    "            query={\n",
    "                \"unix_sock\": \"{}/{}/.s.PGSQL.5432\".format(\n",
    "                    db_socket_dir,  # e.g. \"/cloudsql\"\n",
    "                    cloud_sql_connection_name)  # i.e \"<PROJECT-NAME>:<INSTANCE-REGION>:<INSTANCE-NAME>\"\n",
    "            }\n",
    "        ),\n",
    "        # ... Specify additional properties here.\n",
    "    )\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(request):\n",
    "    \"\"\" Driver function for CLoud Function. Request doesn't do anything. \n",
    "    \"\"\"\n",
    "    # Create GCS client \n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # connect to a bucket \n",
    "    bucket = storage_client.get_bucket('covid19-india-analysis-bucket')\n",
    "    \n",
    "    # Download RAW CSVs from GCS Bucket to Cloud Function temp. storage.\n",
    "    download_folder_bucket(bucket, 'Data/Raw/', '/tmp/')\n",
    "    \n",
    "    # Loading and Transforming data\n",
    "    data = pd.read_csv('/tmp/COVID_India_National.csv', parse_dates=True, index_col=0)\n",
    "    state = pd.read_csv('/tmp/COVID_India_State.csv', parse_dates=True, index_col=0)\n",
    "    # Load and clean test data \n",
    "    test = pd.read_csv('/tmp/COVID_India_Test_data.csv', parse_dates=True, index_col=0)\n",
    "    test = test.loc[~test.index.duplicated(keep='last')]\n",
    "    \n",
    "    # Connect to CloudSQL DB\n",
    "    engine = connect_db()\n",
    "    \n",
    "    # Uploading Data to DB \n",
    "    add_data_table(engine, 'overall_stats', data)\n",
    "    add_data_table(engine, 'states_info', state)\n",
    "    add_data_table(engine, 'testing_stats', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc.\n",
    "Code used to modify the PD stateDF structure for Wide DB structure. Important PD multindex, Pivot table, Melt Examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = make_state_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt stacked Column index Dataframe to long format\n",
    "states.reset_index(inplace=True)\n",
    "new_data = states.melt(id_vars=['Date'])\n",
    "# renaming orphan column with state data\n",
    "new_data.rename(axis = 1, mapper={None: 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting to reshape Status column values(Recovered, Confirmed, Deceased Cases) to columns \n",
    "pivot_data = new_data.pivot_table(index = ['Date','State'],columns = 'Status', values = 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to transfer stacked index Date for to date column\n",
    "final_data = pivot_data.reset_index().set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a series form of the above DF \n",
    "#new_data.groupby(['Date', 'State', 'Status'])['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the Stacked dataframe Again \n",
    "#new_data.pivot_table(values='value', index = 'Date', columns=['State', 'Status'])"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Data_ingestion.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
